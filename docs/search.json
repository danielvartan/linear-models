[
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "General linear models",
    "section": "Overview",
    "text": "Overview\nThis document demonstrates the application of general linear models, with a focus on multiple regression. It utilizes the penguins dataset from the palmerpenguins R package, which contains measurements of penguin species from the Palmer Archipelago. The dataset was originally introduced by Gorman et al. (2014).\n\n\n\n\n\nFigure 1: Artwork by Allison Horst."
  },
  {
    "objectID": "index.html#question",
    "href": "index.html#question",
    "title": "General linear models",
    "section": "Question",
    "text": "Question\nEvery scientific investigation begins with a question. In this case, we will address the following:\nCan bill length and bill depth alone effectively predict flipper length in Adélie penguins?\nImagine a debate between two marine biologists: one claims that bill length and depth could be used to predict flipper length, while the other disagrees.\nTo investigate this question, we will utilize a dataset from the palmerpenguins R package. The relevant variables are bill_length_mm,bill_depth_mm and flipper_length_mm for Adélie penguins. These variables are defined as follows:\n\n\nbill_length_mm: Numerical value representing the bill’s length in millimeters.\n\nbill_depth_mm: Numerical value representing the bill’s depth in millimeters.\n\nflipper_length_mm: Integer value representing the flipper’s length in millimeters.\n\n\n\n\n\n\nFigure 2: Artwork by Allison Horst."
  },
  {
    "objectID": "index.html#hypothesis",
    "href": "index.html#hypothesis",
    "title": "General linear models",
    "section": "Hypothesis",
    "text": "Hypothesis\nTo approach our question, we will apply Popper’s hypothetico-deductive method, also known as the method of conjecture and refutation (Popper, 1979, p. 164). The basic structure of this approach can be summarized as follows:\n\n\n\n\n\nflowchart LR\n  A(P1) --&gt; B(TT)\n  B --&gt; C(EE)\n  C --&gt; D(P2)\n\n\n\n\nFigure 3: Simplified schema of Popper’s hypothetico-deductive method.\n\n\n\n\n“Here \\(\\text{P}_1\\), is the problem from which we start, \\(\\text{TT}\\) (the ‘tentative theory’) is the imaginative conjectural solution which we first reach, for example our first tentative interpretation. \\(\\text{EE}\\) (‘error- elimination’) consists of a severe critical examination of our conjecture, our tentative interpretation: it consists, for example, of the critical use of documentary evidence and, if we have at this early stage more than one conjecture at our disposal, it will also consist of a critical discussion and comparative evaluation of the competing conjectures. \\(\\text{P}_2\\) is the problem situation as it emerges from our first critical attempt to solve our problems. It leads up to our second attempt (and so on).” (Popper, 1979, p. 164)\nAs our tentative theory or main hypothesis, I propose the following:\nBill length and bill depth can effectively predict flipper length in Adélie penguins.\nAs a procedure method, we will employ a method inpired by the Neyman-Pearson approach to data testing (Neyman & Pearson, 1928a, 1928b; Perezgonzalez, 2015), evaluating the following hypotheses:\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{Bill length and bill depth cannot effectively predict flipper length in Adélie penguins} \\\\\n\\text{H}_{a}: \\text{Bill length and bill depth can effectively predict flipper length in Adélie penguins}\n\\end{cases}\n\\]\n\n\n\n\n\n\nTechnically, our procedural method is not a strictly Neyman-Pearson acceptance test; we might refer to it as an improved NHST (Null Hypothesis Significance Testing) approach, based on the original Neyman-Pearson ideas."
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "General linear models",
    "section": "Methods",
    "text": "Methods\nTo test our hypothesis, we will use a general linear model with multiple regression analysis, evaluating the relationship between multiple predictors and a response variable. Here, the response variable is flipper_length_mm, while the predictors are bill_length_mm and bill_depth_mm.\nTo define what we mean by effectively predict” we will establish the following decision criteria:\n\nPredictors should exhibit a statistically significant association with the response variable.\nThe model should satisfy all validity assumptions.\nThe variance explained by the predictors (\\(\\text{R}^{2}_{\\text{adj}}\\)) must exceed 0.5, suggesting a strong association with the response variable (\\(\\text{Cohen's } f^2 = \\cfrac{0.5}{1 - 0.5} = 1\\).)\n\nThis 0.5 threshold is not arbitrary; it represents the average level of variance explained in response variables during observational field studies in ecology, especially when there is limited control over factors influencing variance (Peek et al., 2003).\nFinally, our hypothesis test can be systematized as follows:\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{R}^{2}_{\\text{adj}} \\leq 0.5 \\\\\n\\text{H}_{a}: \\text{R}^{2}_{\\text{adj}} &gt; 0.5\n\\end{cases}\n\\]\nIn addition to an adjusted R-squared greater than 0.5, we will require predictors to show statistically significant associations and for the model to meet all assumptions.\nWe will set the significance level (\\(\\alpha\\)) at 0.05, allowing a 5% chance of a Type I error. A power analysis will be performed to determine the necessary sample size for detecting a significant effect, targeting a power (\\(1 - \\beta\\)) of 0.8.\nAssumption checks will include:\n\nAssessing the normality of residuals through visual inspections, such as Q-Q plots, and statistical tests like the Shapiro-Wilk test.\nEvaluating homoscedasticity using tests like the Breusch-Pagan test to ensure constant variance of residuals across predictor levels.\n\nWe will assess multicollinearity by calculating variance inflation factors (VIF), with a VIF above 10 indicating potential issues. Influential points will be examined using Cook’s distance and leverage values to identify any points that may disproportionately affect model outcomes.\n\n\n\n\n\n\nIt’s important to emphasize that we are assessing predictive power, not establishing causality. Predictive models alone should never be used to infer causal relationships (Arif & MacNeil, 2022)."
  },
  {
    "objectID": "index.html#an-overview-of-general-linear-models",
    "href": "index.html#an-overview-of-general-linear-models",
    "title": "General linear models",
    "section": "An overview of general linear models",
    "text": "An overview of general linear models\nBefore proceeding, let’s briefly overview general linear models, with a focus on multiple regression analysis.\n“[…] A problem of this type is called a problem of multiple linear regression because we are considering the regression of \\(Y\\) on \\(k\\) variables \\(X_{1}, \\dots, X_{k}\\), rather than on just a single variable \\(X\\), and we are assuming also that this regression is a linear function of the parameters \\(\\beta_{0}, \\dots, \\beta_{k}\\). In a problem of multiple linear regressions, we obtain \\(n\\) vectors of observations (\\(x_{i1}. \\dots, x_{ik}, Y_{i}\\)), for \\(i = 1, \\dots, n\\). Here \\(x_{ij}\\) is the observed value of the variable \\(X_{j}\\) for the \\(i\\)th observation. The \\(E(Y)\\) is given by the relation\n\\[\nE(Y_{i}) = \\beta_{0} + \\beta_{1} x_{i1} + \\dots + \\beta_{k} x_{ik}\n\\]\n(DeGroot & Schervish, 2012, p. 738)\nDefinitions\n\nResiduals/Fitted values\n\nFor \\(i = 1, \\dots, n\\), the observed values of \\(\\hat{y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} x_{i}\\) are called fitted values. For \\(i = 1, \\dots, n\\), the observed values of \\(e_{i} = y_{i} - \\hat{y}_{i}\\) are called residuals (DeGroot & Schervish, 2012, p. 717).\n\n\n“[…] regression problems in which the observations \\(Y_{i}, \\dots, Y_{n}\\) […] we shall assume that each observation \\(Y_{i}\\) has a normal distribution, that the observations \\(Y_{1}, \\dots, Y_{n}\\) are independent, and that the observations \\(Y_{1}, \\dots, Y_{n}\\) have the same variance \\(\\sigma^{2}\\). Instead of a single predictor being associated with each \\(Y_{i}\\), we assume that a \\(p\\)-dimensional vector \\(z_{i} = (z_{i0}, \\dots, z_{ip - 1})\\) is associated with each \\(Y_{i}\\)” (DeGroot & Schervish, 2012, p. 736).\n\nGeneral linear model\n\nThe statistical model in which the observations \\(Y_{1}, \\dots, Y_{n}\\) satisfy the following assumptions (DeGroot & Schervish, 2012, p. 738).\n\nAssumptions\n\nAssumption 1\n\nPredictor is known. Either the vectors \\(z_{1}, \\dots , z_{n}\\) are known ahead of time, or they are the observed values of random vectors \\(Z_{1}, \\dots , Z_{n}\\) on whose values we condition before computing the joint distribution of (\\(Y_{1}, \\dots , Y_{n}\\)) (DeGroot & Schervish, 2012, p. 736).\n\nAssumption 2\n\nNormality. For \\(i = 1, \\dots, n\\), the conditional distribution of \\(Y_{i}\\) given the vectors \\(z_{1}, \\dots , z_{n}\\) is a normal distribution (DeGroot & Schervish, 2012, p. 737).\n\n\n(Normality of the error term distribution (Hair, 2019, p. 287))\n\nAssumption 3\n\nLinear mean. There is a vector of parameters \\(\\beta = (\\beta_{0}, \\dots, \\beta_{p - 1})\\) such that the conditional mean of \\(Y_{i}\\) given the values \\(z_{1}, \\dots , z_{n}\\) has the form\n\n\n\\[\nz_{i0} \\beta_{0} + z_{i1} \\beta_{1} + \\cdots + z_{ip - 1} \\beta_{p - 1}\n\\]\nfor \\(i = 1, \\dots, n\\) (DeGroot & Schervish, 2012, p. 737).\n(Linearity of the phenomenon measured (Hair, 2019, p. 287))\n\n\n\n\n\n\nIt is important to clarify that the linear assumption pertains to linearity in the parameters or equivalently, linearity in the coefficients. This means that each predictor is multiplied by its corresponding regression coefficient. However, this does not imply that the relationship between the predictors and the response variable is linear. In fact, a linear model can still effectively capture non-linear relationships between predictors and the response variable by utilizing transformations of the predictors (Cohen et al., 2002).\n\n\n\n\nAssumption 4\n\nCommon variance (homoscedasticity). There is as parameter \\(\\sigma^{2}\\) such the conditional variance of \\(Y_{i}\\) given the values \\(z_{1}, \\dots , z_{n}\\) is \\(\\sigma^{2}\\) for \\(i = 1, \\dots, n\\).\n\n\n(Constant variance of the error terms (Hair, 2019, p. 287))\n\nAssumption 5\n\nIndependence. The random variables \\(Y_{1}, \\dots , Y_{n}\\) are independent given the observed \\(z_{1}, \\dots , z_{n}\\) (DeGroot & Schervish, 2012, p. 737).\n\n\n(Independence of the error terms (Hair, 2019, p. 287))"
  },
  {
    "objectID": "index.html#setting-up-the-environment",
    "href": "index.html#setting-up-the-environment",
    "title": "General linear models",
    "section": "Setting up the environment",
    "text": "Setting up the environment\n\nCodelibrary(broom)\nlibrary(car)\nlibrary(checkmate)\nlibrary(cowplot)\nlibrary(dplyr)\nlibrary(effectsize)\nlibrary(fBasics)\nlibrary(forecast)\nlibrary(ggeffects)\nlibrary(GGally)\nlibrary(ggplot2)\nlibrary(ggpmisc)\nlibrary(ggplotify)\nlibrary(qqplotr)\nlibrary(ggPredict)\nlibrary(glue)\nlibrary(insight)\nlibrary(janitor)\nlibrary(latex2exp)\nlibrary(magrittr)\nlibrary(moments)\nlibrary(nortest)\nlibrary(olsrr)\nlibrary(palmerpenguins)\nlibrary(parameters)\nlibrary(parsnip)\nlibrary(performance)\nlibrary(predict3d)\nlibrary(psychometric)\nlibrary(pwrss)\nlibrary(recipes)\nlibrary(report)\nlibrary(rgl)\nlibrary(rutils)\nlibrary(sandwich)\nlibrary(stats)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(tseries)\nlibrary(viridis)\nlibrary(workflows)\n\n\n\nCodegg_color_hue &lt;- function(n) {\n  hues = seq(15, 375, length = n + 1)\n  hcl(h = hues, l = 65, c = 100)[1:n]\n}\n\n\n\nCodelm_fun &lt;- function(model, fix_all_but = NULL, data = NULL) {\n  checkmate::assert_class(model, \"lm\")\n  \n  checkmate::assert_number(\n    fix_all_but, \n    lower = 1,\n    upper = length(stats::coef(model)) - 1, \n    null.ok = TRUE\n  )\n  \n  coef &lt;- broom::tidy(fit)\n  vars &lt;- letters[seq_len((nrow(coef) - 1))]\n  \n  fixed_vars &lt;- vars\n  \n  if (!is.null(fix_all_but)) {\n    checkmate::assert_data_frame(data)\n    checkmate::assert_subset(coef$term[-1], names(data))\n    \n    for (i in seq_along(fixed_vars)[-fix_all_but]) {\n      fixed_vars[i] &lt;- mean(data[[coef$term[i + 1]]], na.rm = TRUE)\n    }\n    \n    vars &lt;- vars[fix_all_but]\n  }\n  \n  fun_exp &lt;- str2expression(\n      glue::glue(\n        \"function({paste0(vars, collapse = ', ')}) {{\", \"\\n\",\n        \"  {paste0('checkmate::assert_numeric(', vars, ')', collapse = '\\n')}\",\n        \"\\n\\n\",\n        \"  {coef$estimate[1]} +\",\n        \"{paste0(coef$estimate[-1], ' * ', fixed_vars, collapse = ' + ')}\",\n        \"\\n\",\n        \"}}\"\n      )\n    )\n  \n  out &lt;- eval(fun_exp)\n  \n  out\n}\n\n\n\nCodelm_str_fun &lt;- function(\n    model, \n    digits = 3,\n    latex2exp = TRUE,\n    fix_all_but = NULL, # Ignore the intercept coefficient.\n    fix_fun = \"Mean\",\n    coef_names = NULL # Ignore the intercept coefficient.\n  ) {\n  checkmate::assert_class(model, \"lm\")\n  checkmate::assert_number(digits)\n  checkmate::assert_flag(latex2exp)\n  \n  checkmate::assert_number(\n    fix_all_but, \n    lower = 1,\n    upper = length(stats::coef(model)) - 1, \n    null.ok = TRUE\n  )\n  \n  checkmate::assert_string(fix_fun)\n  \n  checkmate::assert_character(\n    coef_names, \n    any.missing = FALSE, \n    len = length(names(stats::coef(model))) - 1,\n    null.ok = TRUE\n  )\n  \n  if (is.null(coef_names)) coef_names &lt;- names(stats::coef(model))[-1]\n  \n  coef &lt;- list()\n  \n  for (i in seq_along(coef_names)) {\n    coef[[coef_names[i]]] &lt;- \n      stats::coef(model) |&gt; \n      magrittr::extract(i + 1) |&gt;\n      rutils:::clear_names() |&gt;\n      round(digits)\n  }\n  \n  coef_names &lt;-\n    coef_names |&gt;\n    stringr::str_replace_all(\"\\\\_|\\\\.\", \" \") |&gt;\n    stringr::str_to_title() |&gt;\n    stringr::str_replace(\" \", \"\")\n  \n  if (!is.null(fix_all_but)) {\n    for (i in seq_along(coef_names)[-fix_all_but]) {\n      coef_names[i] &lt;- paste0(fix_fun, \"(\", coef_names[i], \")\")\n    }\n  }\n  \n  out &lt;- paste0(\n    \"$\", \"y =\", \" \", \n    round(stats::coef(model)[1], digits), \" + \",\n    paste0(coef, \" \\\\times \", coef_names, collapse = \" + \"),\n    \"$\"\n  )\n  \n  out &lt;- out |&gt; stringr::str_replace(\"\\\\+ \\\\-\", \"\\\\- \") \n  \n  if (isTRUE(latex2exp)) {\n    out |&gt;latex2exp::TeX()\n  } else {\n    out\n  }\n}\n\n\n\nCodetest_outlier &lt;- function(\n    x, \n    method = \"iqr\", \n    iqr_mult = 1.5, \n    sd_mult = 3\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_choice(method, c(\"iqr\", \"sd\"))\n  checkmate::assert_number(iqr_mult)\n  checkmate::assert_number(sd_mult)\n\n  if (method == \"iqr\") {\n    iqr &lt;- stats::IQR(x, na.rm = TRUE)\n    min &lt;- stats::quantile(x, 0.25, na.rm = TRUE) - (iqr_mult * iqr)\n    max &lt;- stats::quantile(x, 0.75, na.rm = TRUE) + (iqr_mult * iqr)\n  } else if (method == \"sd\") {\n    min &lt;- mean(x, na.rm = TRUE) - (sd_mult * stats::sd(x, na.rm = TRUE))\n    max &lt;- mean(x, na.rm = TRUE) + (sd_mult * stats::sd(x, na.rm = TRUE))\n  }\n\n  dplyr::if_else(x &gt;= min & x &lt;= max, FALSE, TRUE, missing = FALSE)\n}\n\n\n\nCoderemove_outliers &lt;- function(\n    x, \n    method = \"iqr\", \n    iqr_mult = 1.5, \n    sd_mult = 3\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_choice(method, c(\"iqr\", \"sd\"))\n  checkmate::assert_number(iqr_mult, lower = 1)\n  checkmate::assert_number(sd_mult, lower = 0)\n\n  x |&gt;\n    test_outlier(\n      method = method, \n      iqr_mult = iqr_mult, \n      sd_mult = sd_mult\n    ) %&gt;%\n    `!`() %&gt;%\n    magrittr::extract(x, .)\n}\n\n\n\nCodelist_as_tibble &lt;- function(list) {\n  checkmate::assert_list(list)\n\n  list |&gt;\n    dplyr::as_tibble() |&gt;\n    dplyr::mutate(\n      dplyr::across(\n        .cols = dplyr::everything(),\n        .fns = as.character\n      )\n    ) |&gt;\n    tidyr::pivot_longer(cols = dplyr::everything())\n}\n\n\n\nCodestats_sum &lt;- function(\n    x,\n    name = NULL,\n    na_rm = TRUE,\n    remove_outliers = FALSE,\n    iqr_mult = 1.5,\n    as_list = FALSE\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_string(name, null.ok = TRUE)\n  checkmate::assert_flag(na_rm)\n  checkmate::assert_flag(remove_outliers)\n  checkmate::assert_number(iqr_mult, lower = 1)\n  checkmate::assert_flag(as_list)\n\n  if (isTRUE(remove_outliers)) {\n    x &lt;- x |&gt; remove_outliers(method = \"iqr\", iqr_mult = iqr_mult)\n  }\n\n  out &lt;- list(\n    n = length(x),\n    n_rm_na = length(x[!is.na(x)]),\n    n_na = length(x[is.na(x)]),\n    mean = mean(x, na.rm = na_rm),\n    var = stats::var(x, na.rm = na_rm),\n    sd = stats::sd(x, na.rm = na_rm),\n    min = rutils:::clear_names(stats::quantile(x, 0, na.rm = na_rm)),\n    q_1 = rutils:::clear_names(stats::quantile(x, 0.25, na.rm = na_rm)),\n    median = rutils:::clear_names(stats::quantile(x, 0.5, na.rm = na_rm)),\n    q_3 = rutils:::clear_names(stats::quantile(x, 0.75, na.rm = na_rm)),\n    max = rutils:::clear_names(stats::quantile(x, 1, na.rm = na_rm)),\n    iqr = IQR(x, na.rm = na_rm),\n    skewness = moments::skewness(x, na.rm = na_rm),\n    kurtosis = moments::kurtosis(x, na.rm = na_rm)\n  )\n\n  if (!is.null(name)) out &lt;- append(out, list(name = name), after = 0)\n  \n  if (isTRUE(as_list)) {\n    out\n  } else {\n    out |&gt; list_as_tibble()\n  }\n}\n\n\n\nCodeplot_qq &lt;- function(\n    x,\n    text_size = NULL,\n    na_rm = TRUE,\n    print = TRUE\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_number(text_size, null.ok = TRUE)\n  checkmate::assert_flag(na_rm)\n  checkmate::assert_flag(print)\n\n  if (isTRUE(na_rm)) x &lt;- x |&gt; rutils:::drop_na()\n\n  plot &lt;-\n    dplyr::tibble(y = x) |&gt;\n    ggplot2::ggplot(ggplot2::aes(sample = y)) +\n    ggplot2::stat_qq() +\n    ggplot2::stat_qq_line(color = \"red\", linewidth = 1) +\n    ggplot2::labs(\n      x = \"Theoretical quantiles (Std. normal)\",\n      y = \"Sample quantiles\"\n    ) +\n    ggplot2::theme(text = ggplot2::element_text(size = text_size))\n\n  if (isTRUE(print)) print(plot)\n  \n  invisible(plot)\n}\n\n\n\nCodeplot_hist &lt;- function(\n    x,\n    name = \"x\",\n    bins = 30,\n    stat = \"density\",\n    text_size = NULL,\n    density_line = TRUE,\n    na_rm = TRUE,\n    print = TRUE\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_string(name)\n  checkmate::assert_number(bins, lower = 1)\n  checkmate::assert_choice(stat, c(\"count\", \"density\"))\n  checkmate::assert_number(text_size, null.ok = TRUE)\n  checkmate::assert_flag(density_line)\n  checkmate::assert_flag(na_rm)\n  checkmate::assert_flag(print)\n\n  if (isTRUE(na_rm)) x &lt;- x |&gt; rutils:::drop_na()\n  y_lab &lt;- ifelse(stat == \"count\", \"Frequency\", \"Density\")\n\n  plot &lt;-\n    dplyr::tibble(y = x) |&gt;\n    ggplot2::ggplot(ggplot2::aes(x = y)) +\n    ggplot2::geom_histogram(\n      ggplot2::aes(y = ggplot2::after_stat(!!as.symbol(stat))),\n      bins = 30, \n      color = \"white\"\n    ) +\n    ggplot2::labs(x = name, y = y_lab) +\n    ggplot2::theme(text = ggplot2::element_text(size = text_size))\n\n  if (stat == \"density\" && isTRUE(density_line)) {\n    plot &lt;- plot + ggplot2::geom_density(color = \"red\", linewidth = 1)\n  }\n\n  if (isTRUE(print)) print(plot)\n  \n  invisible(plot)\n}\n\n\n\nCodeplot_ggally &lt;- function(\n    data,\n    cols = names(data),\n    mapping = NULL,\n    axis_labels = \"none\",\n    na_rm = TRUE,\n    text_size = NULL\n  ) {\n  checkmate::assert_tibble(data)\n  checkmate::assert_character(cols)\n  checkmate::assert_subset(cols, names(data))\n  checkmate::assert_class(mapping, \"uneval\", null.ok = TRUE)\n  checkmate::assert_choice(axis_labels, c(\"show\", \"internal\", \"none\"))\n  checkmate::assert_flag(na_rm)\n  checkmate::assert_number(text_size, null.ok = TRUE)\n\n  out &lt;-\n    data|&gt;\n    dplyr::select(dplyr::all_of(cols))|&gt;\n    dplyr::mutate(\n      dplyr::across(\n      .cols = dplyr::where(hms::is_hms),\n      .fns = ~ midday_trigger(.x)\n      ),\n      dplyr::across(\n        .cols = dplyr::where(\n          ~ !is.character(.x) && !is.factor(.x) && !is.numeric(.x)\n        ),\n        .fns = ~ as.numeric(.x)\n      )\n    )\n\n  if (isTRUE(na_rm)) out &lt;- out|&gt; tidyr::drop_na(dplyr::all_of(cols))\n\n  if (is.null(mapping)) {\n    plot &lt;-\n      out|&gt;\n      GGally::ggpairs(\n        lower = list(continuous = \"smooth\"),\n        axisLabels = axis_labels\n      ) \n  } else {\n    plot &lt;-\n      out|&gt;\n      GGally::ggpairs(\n        mapping = mapping,\n        axisLabels = axis_labels\n      ) +\n      viridis::scale_color_viridis(\n        begin = 0.25,\n        end = 0.75,\n        discrete = TRUE,\n        option = \"viridis\"\n      ) +\n      viridis::scale_fill_viridis(\n        begin = 0.25,\n        end = 0.75,\n        discrete = TRUE,\n        option = \"viridis\"\n      )\n  }\n\n  plot &lt;- \n    plot +\n    ggplot2::theme(text = ggplot2::element_text(size = text_size))\n\n  print(plot)\n  \n  invisible(plot)\n}\n\n\n\nCodetest_normality &lt;- function(x,\n                           name = \"x\",\n                           remove_outliers = FALSE,\n                           iqr_mult = 1.5,\n                           log_transform = FALSE,\n                           density_line = TRUE,\n                           text_size = NULL,\n                           print = TRUE) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_string(name)\n  checkmate::assert_flag(remove_outliers)\n  checkmate::assert_number(iqr_mult, lower = 1)\n  checkmate::assert_flag(log_transform)\n  checkmate::assert_flag(density_line)\n  checkmate::assert_number(text_size, null.ok = TRUE)\n  checkmate::assert_flag(print)\n\n  n &lt;- x |&gt; length()\n  n_rm_na &lt;- x |&gt; rutils:::drop_na() |&gt; length()\n\n  if (isTRUE(remove_outliers)) {\n    x &lt;- x |&gt; remove_outliers(method = \"iqr\", iqr_mult = iqr_mult)\n  }\n\n  if (isTRUE(log_transform)) {\n    x &lt;-\n      x |&gt;\n      log() |&gt;\n      drop_inf()\n  }\n\n  if (n_rm_na &gt;= 7) {\n    ad &lt;- x |&gt; nortest::ad.test()\n\n    cvm &lt;-\n      x |&gt;\n      nortest::cvm.test() |&gt;\n      rutils::shush()\n  } else {\n    ad &lt;- NULL\n    cmv &lt;- NULL\n  }\n\n  bonett &lt;- x |&gt; moments::bonett.test()\n\n  # See also `Rita::DPTest()` (just for Omnibus (K) tests).\n  dagostino &lt;-\n    x |&gt;\n    fBasics::dagoTest() |&gt;\n    rutils::shush()\n\n  jarque_bera &lt;-\n    rutils:::drop_na(x) |&gt;\n    tseries::jarque.bera.test()\n\n  if (n_rm_na &gt;= 4) {\n    lillie_ks &lt;- x |&gt; nortest::lillie.test()\n  } else {\n    lillie_ks &lt;- NULL\n  }\n\n  pearson &lt;- x |&gt; nortest::pearson.test()\n\n  if (n_rm_na &gt;= 5 && n_rm_na &lt;= 5000) {\n    sf &lt;- x |&gt; nortest::sf.test()\n  } else {\n    sf &lt;- NULL\n  }\n\n  if (n_rm_na &gt;= 3 && n_rm_na &lt;= 3000) {\n    shapiro &lt;- x |&gt; stats::shapiro.test()\n  } else {\n    shapiro &lt;- NULL\n  }\n\n  qq_plot &lt;- x |&gt; plot_qq(text_size = text_size, print = FALSE)\n\n  hist_plot &lt;-\n    x |&gt;\n    plot_hist(\n      name = name,\n      text_size = text_size,\n      density_line = density_line,\n      print = FALSE\n      )\n\n  grid_plot &lt;- cowplot::plot_grid(hist_plot, qq_plot, ncol = 2, nrow = 1)\n\n  out &lt;- list(\n    stats = stats_sum(\n      x,\n      name = name,\n      na_rm = TRUE,\n      remove_outliers = FALSE,\n      as_list = TRUE\n    ),\n    params = list(\n      name = name,\n      remove_outliers = remove_outliers,\n      log_transform = log_transform,\n      density_line = density_line\n    ),\n\n    ad = ad,\n    bonett = bonett,\n    cvm = cvm,\n    dagostino = dagostino,\n    jarque_bera = jarque_bera,\n    lillie_ks = lillie_ks,\n    pearson = pearson,\n    sf = sf,\n    shapiro = shapiro,\n\n    hist_plot = hist_plot,\n    qq_plot = qq_plot,\n    grid_plot = grid_plot\n  )\n\n  if (isTRUE(print)) print(grid_plot)\n\n  invisible(out)\n}\n\n\n\nCodenormality_sum &lt;- function(\n    x, \n    round = FALSE, \n    digits = 5, \n    only_p_value = FALSE, \n    ...\n  ) {\n  checkmate::assert_numeric(x)\n  checkmate::assert_flag(round)\n  checkmate::assert_number(digits)\n  checkmate::assert_flag(only_p_value)\n\n  stats &lt;- test_normality(x, print = FALSE, ...)\n\n  out &lt;- dplyr::tibble(\n    test = c(\n      \"Anderson-Darling\",\n      \"Bonett-Seier\",\n      \"Cramér-von Mises\",\n      \"D'Agostino Omnibus Test\",\n      \"D'Agostino Skewness Test\",\n      \"D'Agostino Kurtosis Test\",\n      \"Jarque–Bera\",\n      \"Lilliefors (K-S)\",\n      \"Pearson chi-square\",\n      \"Shapiro-Francia\",\n      \"Shapiro-Wilk\"\n    ),\n    statistic_1 = c(\n      stats$ad$statistic,\n      stats$bonett$statistic[1],\n      stats$cvm$statistic,\n      attr(stats$dagostino, \"test\")$statistic[1],\n      attr(stats$dagostino, \"test\")$statistic[2],\n      attr(stats$dagostino, \"test\")$statistic[3],\n      stats$jarque_bera$statistic,\n      stats$lillie_ks$statistic,\n      stats$pearson$statistic,\n      ifelse(is.null(stats$shapiro), NA, stats$shapiro$statistic),\n      ifelse(is.null(stats$sf), NA, stats$sf$statistic)\n    ),\n    statistic_2 = c(\n      as.numeric(NA),\n      stats$bonett$statistic[2],\n      as.numeric(NA),\n      as.numeric(NA),\n      as.numeric(NA),\n      as.numeric(NA),\n      stats$jarque_bera$parameter,\n      as.numeric(NA),\n      as.numeric(NA),\n      as.numeric(NA),\n      as.numeric(NA)\n    ),\n    p_value = c(\n      stats$ad$p.value,\n      stats$bonett$p.value,\n      stats$cvm$p.value,\n      attr(stats$dagostino, \"test\")$p.value[1],\n      attr(stats$dagostino, \"test\")$p.value[2],\n      attr(stats$dagostino, \"test\")$p.value[3],\n      stats$jarque_bera$p.value,\n      stats$lillie_ks$p.value,\n      stats$pearson$p.value,\n      ifelse(is.null(stats$shapiro), NA, stats$shapiro$p.value),\n      ifelse(is.null(stats$sf), NA, stats$sf$p.value)\n    )\n  )\n\n  if (isTRUE(only_p_value)) out &lt;- out |&gt; dplyr::select(test, p_value)\n  \n  if (isTRUE(round)) {\n    out |&gt;\n      dplyr::mutate(\n        dplyr::across(\n          .cols = dplyr::where(is.numeric),\n          .fns = ~ round(.x, digits)\n        ))\n  } else {\n    out\n  }\n}"
  },
  {
    "objectID": "index.html#preparing-the-data",
    "href": "index.html#preparing-the-data",
    "title": "General linear models",
    "section": "Preparing the data",
    "text": "Preparing the data\nAssumption 1 is satisfied, as the predictors are known.\n\nCodedata &lt;- \n  palmerpenguins::penguins |&gt; \n  dplyr::filter(species == \"Adelie\") |&gt;\n  dplyr::select(bill_length_mm, bill_depth_mm, flipper_length_mm) |&gt;\n  tidyr::drop_na()\n\n\nCodedata\n\n\nTable 1: Data frame with morphological measurements of penguin species from the Palmer Archipelago.\n\n\n\n\n  \n\n\n\n\n\n\n\nCodereport::report(data)\n#&gt; The data contains 151 observations of the following 3 variables:\n#&gt; \n#&gt;   - bill_length_mm: n = 151, Mean = 38.79, SD = 2.66, Median = 38.80, MAD =\n#&gt; 2.97, range: [32.10, 46], Skewness = 0.16, Kurtosis = -0.16, 0% missing\n#&gt;   - bill_depth_mm: n = 151, Mean = 18.35, SD = 1.22, Median = 18.40, MAD =\n#&gt; 1.19, range: [15.50, 21.50], Skewness = 0.32, Kurtosis = -0.06, 0% missing\n#&gt;   - flipper_length_mm: n = 151, Mean = 189.95, SD = 6.54, Median = 190.00, MAD\n#&gt; = 7.41, range: [172, 210], Skewness = 0.09, Kurtosis = 0.33, 0% missing"
  },
  {
    "objectID": "index.html#performing-a-power-analysis",
    "href": "index.html#performing-a-power-analysis",
    "title": "General linear models",
    "section": "Performing a power analysis",
    "text": "Performing a power analysis\nFirst we will perform a a posteriori power analysis to determine the sample size needed to achieve a power (\\(1 - \\beta\\)) of 0.8, given an \\(R^2\\) of 0.5, a significance level (\\(\\alpha\\)) of 0.05, and 2 predictors. It’s a a posterior analysis because we already have the data in hand. It’s a good practice to perform a power analysis before running the model to ensure that the sample size is adequate.\nThe results show that we need at least 14 observations for each variable to achieve the desired power. We have 151 observations, which is more than enough.\n\nCodepre_pwr &lt;- pwrss::pwrss.f.reg(\n  r2 = 0.5, \n  k = 2,\n  power = 0.80,\n  alpha = 0.05\n)\n#&gt;  Linear Regression (F test) \n#&gt;  R-squared Deviation from 0 (zero) \n#&gt;  H0: r2 = 0 \n#&gt;  HA: r2 &gt; 0 \n#&gt;  ------------------------------ \n#&gt;   Statistical power = 0.8 \n#&gt;   n = 14 \n#&gt;  ------------------------------ \n#&gt;  Numerator degrees of freedom = 2 \n#&gt;  Denominator degrees of freedom = 10.144 \n#&gt;  Non-centrality parameter = 13.144 \n#&gt;  Type I error rate = 0.05 \n#&gt;  Type II error rate = 0.2\n\n\n\nCodepwrss::power.f.test(\n  ncp = pre_pwr$ncp,\n  df1 = pre_pwr$df1,\n  df2 = pre_pwr$df2,\n  alpha = pre_pwr$parms$alpha,\n  plot = TRUE\n)\n\n\n\n\n\n\n#&gt;  power ncp.alt ncp.null alpha df1      df2   f.crit\n#&gt;    0.8  13.144        0  0.05   2 10.14432 4.083657\n\nIs the data size greater or equal to the required size?\n\nCodedata |&gt; \n  tidyr::drop_na() |&gt; \n  nrow() |&gt;\n  magrittr::is_weakly_greater_than(pre_pwr$n)\n#&gt; [1] TRUE"
  },
  {
    "objectID": "index.html#checking-distributions",
    "href": "index.html#checking-distributions",
    "title": "General linear models",
    "section": "Checking distributions",
    "text": "Checking distributions\nThe data show fairly normal distributions. It seems that the bill_length_mm and bill_depth_mm variables appear slightly skewed, while the flipper_length_mm variable is more symmetric.\n\n\nBill length (mm)\nBill depth (mm)\nFlipper length (mm)\n\n\n\nCodedata |&gt;\n  dplyr::pull(bill_length_mm) |&gt; \n  stats_sum(name = \"Bill length (mm)\")\n\n\nTable 2: Statistics for the bill_length_mm variable.\n\n\n\n\n  \n\n\n\n\n\n\nCodedata |&gt; \n  dplyr::pull(bill_length_mm) |&gt; \n  test_normality(name = \"Bill length (mm)\")\n#&gt; Registered S3 method overwritten by 'quantmod':\n#&gt;   method            from\n#&gt;   as.zoo.data.frame zoo\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Histogram of the bill_length_mm variable with a kernel density estimate, along with a quantile-quantile (Q-Q) plot between the variable and the theoretical quantiles of the normal distribution.\n\n\n\n\nCodedata |&gt; \n  dplyr::pull(bill_depth_mm) |&gt; \n  stats_sum(name = \"Bill depth (mm)\")\n\n\nTable 3: Summary statistics for the bill_depth_mm variable.\n\n\n\n\n  \n\n\n\n\n\n\nCodedata |&gt; \n  dplyr::pull(bill_depth_mm) |&gt; \n  test_normality(name = \"Bill depth (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Histogram of the bill_depth_mm variable with a kernel density estimate, along with a quantile-quantile (Q-Q) plot between the variable and the theoretical quantiles of the normal distribution.\n\n\n\n\nCodedata |&gt; \n  dplyr::pull(flipper_length_mm) |&gt; \n  stats_sum(name = \"Flipper length (mm)\")\n\n\nTable 4: Summary statistics for the flipper_length_mm variable.\n\n\n\n\n  \n\n\n\n\n\n\nCodedata |&gt; \n  dplyr::pull(flipper_length_mm) |&gt; \n  test_normality(name = \"Flipper length (mm)\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Histogram of the flipper_length_mm variable with a kernel density estimate, along with a quantile-quantile (Q-Q) plot between the variable and the theoretical quantiles of the normal distribution."
  },
  {
    "objectID": "index.html#checking-correlations",
    "href": "index.html#checking-correlations",
    "title": "General linear models",
    "section": "Checking correlations",
    "text": "Checking correlations\nBoth bill_length_mm and bill_depth_mm are positively correlated with flipper_length_mm in a significant manner. No non-linear relationships are observed.\nCodedata |&gt; \n  plot_ggally() |&gt; \n  rutils::shush()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Correlation matrix of bill_length_mm, bill_depth_mm, and flipper_length_mm variables."
  },
  {
    "objectID": "index.html#checking-for-outliers",
    "href": "index.html#checking-for-outliers",
    "title": "General linear models",
    "section": "Checking for outliers",
    "text": "Checking for outliers\nA few minor outliers are present in the bill_length_mm and flipper_length_mm variables. We could remove these outliers, but they are not extreme and do not appear to be errors.\nA few observations were flagged with Cook’s D values greater than the threshold. One of them (129th) was particularly influential, so it was removed from the dataset.\nBoxplots\n\nCodecolors &lt;- gg_color_hue(3)\n\n\nCodedata |&gt; \n  tidyr::pivot_longer(-flipper_length_mm) |&gt;\n  ggplot2::ggplot(ggplot2::aes(x = name, y = value, fill = name)) +\n  ggplot2::geom_boxplot(\n    outlier.colour = \"red\", \n    outlier.shape = 1,\n    width = 0.75\n  ) +\n  ggplot2::geom_jitter(width = 0.3, alpha = 0.1, color = \"black\", size = 0.5) +\n  ggplot2::labs(x = \"Variable\", y = \"Value\", fill = ggplot2::element_blank()) +\n  ggplot2::scale_fill_manual(\n    labels = c(\"Bill length (mm)\", \"Bill depth (mm)\"),\n    breaks = c(\"bill_length_mm\", \"bill_depth_mm\"),\n    values = gg_color_hue(3)[1:2]\n  ) +\n  ggplot2::coord_flip() +\n  ggplot2::theme(\n    axis.title.y = ggplot2::element_blank(),\n    axis.text.y = ggplot2::element_blank(),\n    axis.ticks.y = ggplot2::element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Boxplots of the bill_length_mm and bill_depth_mm variables, with outliers highlighted in red and other data indicated by jittered points.\n\n\nCodedata |&gt; \n  tidyr::pivot_longer(flipper_length_mm) |&gt;\n  ggplot2::ggplot(ggplot2::aes(x = name, y = value, fill = name)) +\n  ggplot2::geom_boxplot(\n    outlier.colour = \"red\", \n    outlier.shape = 1,\n    width = 0.5\n  ) +\n  ggplot2::geom_jitter(width = 0.2, alpha = 0.1, color = \"black\", size = 0.5) +\n  ggplot2::scale_fill_manual(\n    labels = \"Flipper length (mm)\",\n    values = gg_color_hue(3) |&gt; dplyr::last()\n  ) +\n  ggplot2::labs(x = \"Variable\", y = \"Value\", fill = ggplot2::element_blank()) +\n  ggplot2::coord_flip() +\n  ggplot2::theme(\n    axis.title.y = ggplot2::element_blank(),\n    axis.text.y = ggplot2::element_blank(),\n    axis.ticks.y = ggplot2::element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Boxplot of the flipper_length_mm variable, with outliers highlighted in red and other data indicated by jittered points.\n\n\nCook’s distance\nThe Cook’s distance measures each observation’s influence on the model’s fitted values. It is considered one of the most representative metrics for assessing overall influence (Hair, 2019).\nA common practice is to flag observations with a Cook’s distance of 1.0 or greater. However, a more conservative threshold of \\(4 / (n - k - 1)\\), where \\(n\\) is the sample size and \\(k\\) is the number of independent variables, is suggested as a more conservative measure in small samples or for use with larger datasets (Hair, 2019).\nLearn more about Cook’s D in: Cook (1977); Cook (1979).\n\nCodecooks_d_cut_off &lt;- 4 / (nrow(data) - 2 - 1)\n\ncooks_d_cut_off\n#&gt; [1] 0.02702703\n\n\n\nCodeform &lt;- formula(flipper_length_mm ~ bill_length_mm + bill_depth_mm)\n\n\n\nCodefit &lt;- lm(form, data = data)\n\n\n\nCodecooks_obs &lt;- \n  fit |&gt; \n  stats::cooks.distance() %&gt;%\n  magrittr::is_greater_than(cooks_d_cut_off) |&gt;\n  which() |&gt;\n  `names&lt;-`(NULL)\n\nfit |&gt;\n  stats::cooks.distance() |&gt;\n  magrittr::extract(cooks_obs)\n#&gt;         14         90        122        129 \n#&gt; 0.05229124 0.02997213 0.03644541 0.12296893\n\n\nCodeplot &lt;- \n  fit |&gt; \n  olsrr::ols_plot_cooksd_bar(type = 2, print_plot = FALSE)\n\n# The following procedure changes the plot aesthetics.\nq &lt;- plot$plot + ggplot2::labs(title = ggplot2::element_blank())\nq &lt;- q |&gt; ggplot2::ggplot_build()\nq$data[[5]]$label &lt;- \"\"\n\nq |&gt; ggplot2::ggplot_gtable() |&gt; ggplotify::as.ggplot()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Cook’s distance for each observation along with a threshold line at \\(4 / (n - k - 1)\\).\n\n\nOutlier removal\nOutlier detection methods indicate which observations are unusual or influential, and it’s our job to determine why certain observations stand out (Struck, 2024). In this scenario, a observational error or a unique characteristic of the penguin species might be causing some distortions.\nFor practical reasons, I will remove the 129th observation for now. However, it’s crucial to review the model assumptions before making this decision. Violating an assumption might cause many observations to be incorrectly labeled as outliers.\n\nCodedata &lt;- data |&gt; dplyr::slice(-129)"
  },
  {
    "objectID": "index.html#fitting-the-model",
    "href": "index.html#fitting-the-model",
    "title": "General linear models",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nCoderecipe &lt;- \n  data |&gt;\n  recipes::recipe(form) |&gt;\n  rutils::shush()\n\n\n\nCodemodel &lt;- \n  parsnip::linear_reg() |&gt; \n  parsnip::set_engine(\"lm\") |&gt;\n  parsnip::set_mode(\"regression\")\n\n\n\nCodeworkflow &lt;- \n  workflows::workflow() |&gt;\n  workflows::add_recipe(recipe) |&gt;\n  workflows::add_model(model)\n\n\n\nCodefit &lt;- workflow |&gt; parsnip::fit(data)\n\n\nCodefit |&gt;\n  broom::tidy() |&gt; \n  janitor::adorn_rounding(5)\n\n\nTable 5: Output from the model fitting process showing the estimated coefficients, standard errors, test statistics, and p-values for the terms in the linear regression model.\n\n\n\n\n  \n\n\n\n\n\n\nCodefit |&gt; \n  broom::augment(data) |&gt;\n  janitor::adorn_rounding(5)\n\n\nTable 6: Model summary table displaying predictions and residuals, along with the variables used in the model.\n\n\n\n\n  \n\n\n\n\n\n\nCodefit |&gt; \n  broom::glance() |&gt; \n  tidyr::pivot_longer(cols = dplyr::everything()) |&gt;\n  janitor::adorn_rounding(10)\n\n\nTable 7: Summary of model fit statistics showing key metrics including R-squared, adjusted R-squared, sigma, statistic, p-value, degrees of freedom, log-likelihood, AIC, BIC, and deviance.\n\n\n\n\n  \n\n\n\n\n\n\n\nCodefit_engine &lt;- fit |&gt; parsnip::extract_fit_engine()\n\nfit_engine |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; stats::lm(formula = ..y ~ ., data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -17.7249  -3.1509  -0.0638   3.7849  16.4935 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Estimate Std. Error t value             Pr(&gt;|t|)    \n#&gt; (Intercept)    147.8358     8.6512  17.088 &lt; 0.0000000000000002 ***\n#&gt; bill_length_mm   0.4832     0.2013   2.401              0.01760 *  \n#&gt; bill_depth_mm    1.2674     0.4348   2.915              0.00411 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.934 on 147 degrees of freedom\n#&gt; Multiple R-squared:  0.1387, Adjusted R-squared:  0.127 \n#&gt; F-statistic: 11.84 on 2 and 147 DF,  p-value: 0.00001711\n\n\nCodefit_engine |&gt; parameters::standardize_parameters()\n\n\nTable 8: Standardized model parameters (coefficients) along with their ranges, based on a 95% confidence interval.\n\n\n\n\n  \n\n\n\n\n\n\n\nCode# A jerry-rigged solution to fix issues related to modeling using the pipe.\n\nfit_engine_2 &lt;- lm(form, data = data)\n\n\n\nCodereport::report(fit_engine_2)\n#&gt; We fitted a linear model (estimated using OLS) to predict flipper_length_mm\n#&gt; with bill_length_mm and bill_depth_mm (formula: flipper_length_mm ~\n#&gt; bill_length_mm + bill_depth_mm). The model explains a statistically\n#&gt; significant and moderate proportion of variance (R2 = 0.14, F(2, 147) =\n#&gt; 11.84, p &lt; .001, adj. R2 = 0.13). The model's intercept, corresponding to\n#&gt; bill_length_mm = 0 and bill_depth_mm = 0, is at 147.84 (95% CI [130.74,\n#&gt; 164.93], t(147) = 17.09, p &lt; .001). Within this model:\n#&gt; \n#&gt;   - The effect of bill length mm is statistically significant and positive\n#&gt; (beta = 0.48, 95% CI [0.09, 0.88], t(147) = 2.40, p = 0.018; Std. beta =\n#&gt; 0.20, 95% CI [0.04, 0.37])\n#&gt;   - The effect of bill depth mm is statistically significant and positive\n#&gt; (beta = 1.27, 95% CI [0.41, 2.13], t(147) = 2.92, p = 0.004; Std. beta =\n#&gt; 0.24, 95% CI [0.08, 0.41])\n#&gt; \n#&gt; Standardized parameters were obtained by fitting the model on a standardized\n#&gt; version of the dataset. 95% Confidence Intervals (CIs) and p-values were\n#&gt; computed using a Wald t-distribution approximation."
  },
  {
    "objectID": "index.html#inspecting-the-model-fit",
    "href": "index.html#inspecting-the-model-fit",
    "title": "General linear models",
    "section": "Inspecting the model fit",
    "text": "Inspecting the model fit\nPredictions\nIn a multiple linear regression with two predictors, the model is fit by adjusting a plane to the data points.\nCodeuser_matrix &lt;-\n  dplyr::tribble(\n    ~a,         ~b,         ~c,          ~d,\n    0.6233152,  -0.7817951, -0.01657271, 0,\n    0.1739255,  0.1179437,  0.97767037,  0,\n    -0.7623830, -0.6122792, 0.20949011,  0,\n    0,          0,          0,           1\n  ) |&gt;\n  as.matrix() |&gt;\n  `colnames&lt;-`(NULL)\n\nfit_engine |&gt;\n  predict3d::predict3d(\n    xlab = \"Bill length (mm)\",\n    ylab = \"Bill depth (mm)\",\n    zlab = \"Flipper length (mm)\",\n    radius = 0.75,\n    type = \"s\",\n    color = \"red\",\n    show.subtitle = FALSE,\n    show.error = FALSE\n  )\n\nrgl::view3d(userMatrix = user_matrix, zoom = 0.9)\n\nrgl::rglwidget(elementId = \"1st\") |&gt; rutils::shush()\n\n\n\n\n\n\n\n\n\n\nFigure 11: A 3D visualization of the fitted model: the plane represents the model, while the points represent the observed data. Use the mouse to explore.\n\n\nCodelimits &lt;- \n  stats::predict(fit_engine, interval = \"prediction\") |&gt;\n  dplyr::as_tibble() |&gt;\n  rutils::shush()\n\nfit |&gt;\n  broom::augment(data) |&gt;\n  dplyr::bind_cols(limits) |&gt;\n  ggplot2::ggplot(ggplot2::aes(flipper_length_mm, .pred)) +\n  # ggplot2::geom_ribbon(\n  #   mapping = ggplot2::aes(ymin = lwr, ymax = upr),\n  #   alpha = 0.2\n  # ) +\n  ggplot2::geom_ribbon(\n    mapping = ggplot2::aes(\n      ymin = stats::predict(stats::loess(lwr ~ flipper_length_mm)),\n      ymax = stats::predict(stats::loess(upr ~ flipper_length_mm)),\n    ),\n    alpha = 0.2\n  ) +\n  ggplot2::geom_smooth(\n    mapping = ggplot2::aes(y = lwr),\n    se = FALSE,\n    method = \"loess\",\n    formula = y ~ x,\n    linetype = \"dashed\",\n    linewidth = 0.2,\n    color = \"black\"\n  ) +\n  ggplot2::geom_smooth(\n    mapping = ggplot2::aes(y = upr),\n    se = FALSE,\n    method = \"loess\",\n    formula = y ~ x,\n    linetype = \"dashed\",\n    linewidth = 0.2,\n    color = \"black\"\n  ) +\n  ggplot2::geom_point() +\n  ggplot2::geom_abline(intercept = 0, slope = 1, color = \"red\") +\n  ggplot2::labs(\n    x = \"Observed\", \n    y = \"Predicted\", \n    subtitle = latex2exp::TeX(\n      paste0(\n        lm_str_fun(fit_engine, digits = 3, latex2exp = FALSE), \" | \",\n        \"$R^{2} = \", round(broom::glance(fit)$r.squared, 3), \"$ | \",\n        \"$R^{2}_{adj} = \", round(broom::glance(fit)$adj.r.squared, 3), \"$\"\n      )\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Relation between observed and predicted values. The red line is a 45-degree line originating from the plane’s origin and represents a perfect fit. The shaded area depicts a smoothed version of the 95% confidence of the prediction interval.\n\n\nAdjusted predictions\nIf we keep all predictors fixed except one, we can observe the regression line between that independent variable and the dependent variable. Here, I present different visualizations of the fitted model. This is important for understanding how each predictor is associated with the outcome.\nCodefit |&gt;\n  broom::augment(data) |&gt;\n  ggplot2::ggplot(ggplot2::aes(bill_length_mm, flipper_length_mm)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_line(\n    ggplot2::aes(y = .pred, color = \"Prediction\"),\n    linewidth = 0.5,\n    alpha = 0.5\n  ) +\n  ggplot2::geom_function(\n    ggplot2::aes(y = .pred, color = \"Adjusted prediction\"),\n    fun = lm_fun(fit_engine, fix_all_but = 1, data = data),\n    linewidth = 1\n  ) +\n  ggplot2::labs(\n    x = \"Bill length (mm)\",\n    y = \"Flipper length (mm)\",\n    subtitle = lm_str_fun(fit_engine, fix_all_but = 1),\n    color = ggplot2::element_blank()\n  ) +\n  ggplot2::scale_color_manual(\n    values = c(\"Prediction\" = \"blue\", \"Adjusted prediction\" = \"red\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Model prediction (blue line) and adjusted prediction (red line) plotted against a scatter plot of the dependent variable (flipper_length_mm) and one of the independent variables (bill_length_mm). The adjusted prediction is calculated by holding the bill_depth_mm variable constant at its mean value.\n\n\nCodefit |&gt;\n  broom::augment(data) |&gt;\n  ggplot2::ggplot(ggplot2::aes(bill_depth_mm, flipper_length_mm)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_line(\n    ggplot2::aes(y = .pred, color = \"Prediction\"), \n    linewidth = 0.5,\n    alpha = 0.5\n  ) +\n  ggplot2::geom_function(\n    ggplot2::aes(y = .pred, color = \"Adjusted prediction\"),\n    fun = lm_fun(fit_engine, fix_all_but = 2, data = data),\n    linewidth = 1\n  ) +\n  ggplot2::labs(\n    x = \"Bill depth (mm)\",\n    y = \"Flipper length (mm)\",\n    subtitle = lm_str_fun(fit_engine, fix_all_but = 2),\n    color = ggplot2::element_blank()\n  ) +\n  ggplot2::scale_color_manual(\n    values = c(\"Prediction\" = \"blue\", \"Adjusted prediction\" = \"red\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: Model prediction (blue line) and adjusted prediction (red line) plotted against a scatter plot of the dependent variable (flipper_length_mm) and one of the independent variables (bill_depth_mm). The adjusted prediction is calculated by holding the bill_length_mm variable constant at its mean value.\n\n\n\nCodefit_engine_2 |&gt;\n  ggeffects::predict_response(\n    terms = c(\"bill_length_mm\", \"bill_depth_mm\")\n  ) |&gt; \n  plot(show_data = TRUE, verbose = FALSE) +\n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    x = \"Bill length (mm)\",\n    y = \"Flipper length (mm)\",\n    color = \"Bill depth (mm)\"\n  ) +\n  ggplot2::theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15: Relationship between flipper_length_mm and bill_length_mm, with data points represented as dots. The three lines show model predictions for different values of the variable bill_depth_mm, with the shaded areas representing confidence intervals.\n\n\nPosterior predictive checks\nPosterior predictive checks are a Bayesian technique used to assess model fit by comparing observed data to data simulated from the posterior predictive distribution (i.e., the distribution of potential unobserved values given the observed data). These checks help identify systematic discrepancies between the observed and simulated data, providing insight into whether the chosen model (or distributional family) is appropriate. Ideally, the model-predicted lines should closely match the observed data patterns.\nCodediag_sum_plots &lt;- \n  fit_engine_2 |&gt; \n  performance::check_model(\n    panel = FALSE,\n    colors = c(\"red\", \"black\", \"black\")\n  ) |&gt;\n  plot() |&gt;\n  rutils::shush()\n\ndiag_sum_plots$PP_CHECK +\n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    subtitle = ggplot2::element_blank(),\n    x = \"Flipper length (mm)\",\n  ) +\n  ggplot2::theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: Posterior predictive checks for the model. The red line represents the observed data, while the black lines represent the model-predicted data."
  },
  {
    "objectID": "index.html#performing-model-diagnostics",
    "href": "index.html#performing-model-diagnostics",
    "title": "General linear models",
    "section": "Performing model diagnostics",
    "text": "Performing model diagnostics\n\n\n\n\n\n\nBefore using objective assumption tests (e.g., Anderson–Darling test), it’s important to note that they may be not advisable in some contexts. In larger samples, these tests can be overly sensitive to minor deviations, while in smaller samples, they may not detect significant deviations. Additionally, they might overlook visual patterns that are not captured by a single metric. Therefore, visual assessment of diagnostic plots may be a better way (Kozak & Piepho, 2018; Schucany & Ng, 2006; Shatz, 2024). For a straightforward critique of normality tests specifically, refer to this article by Greener (2020).\n\n\n\nNormality\nAssumption 2 is satisfied, as the residuals shown a normal distribution in 11 types of normality tests with different approaches (e.g., moments, regression/correlations; ECDFs).\nVisual inspection\nCodefit_engine |&gt;\n  stats::residuals() |&gt;\n  test_normality(name = \"Residuals\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 17: Histogram of the model residuals with a kernel density estimate, along with a quantile-quantile (Q-Q) plot between the residuals and the theoretical quantiles of the normal distribution.\n\n\nCodefit |&gt; \n  broom::augment(data) |&gt;\n  dplyr::select(.resid) |&gt;\n  tidyr::pivot_longer(.resid) |&gt;\n  ggplot2::ggplot(ggplot2::aes(x = name, y = value, fill = name)) +\n  ggplot2::geom_boxplot(\n    outlier.colour = \"red\", \n    outlier.shape = 1,\n    width = 0.5\n  ) +\n  ggplot2::geom_jitter(width = 0.2, alpha = 0.1, color = \"black\", size = 0.5) +\n  ggplot2::scale_fill_manual(\n    labels = \"Residuals\",\n    values = gg_color_hue(1)\n  ) +\n  ggplot2::labs(x = \"Variable\", y = \"Value\", fill = ggplot2::element_blank()) +\n  ggplot2::coord_flip() +\n  ggplot2::theme(\n    axis.title.y = ggplot2::element_blank(),\n    axis.text.y = ggplot2::element_blank(),\n    axis.ticks.y = ggplot2::element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 18: Boxplot of model residuals with outliers highlighted in red and other residuals indicated by jittered points.\n\n\nCodefit_engine |&gt;\n  stats::residuals() |&gt;\n  stats_sum(name = \"Residuals\")\n\n\nTable 9: Summary statistics of model residuals.\n\n\n\n\n  \n\n\n\n\n\n\nTests\nIt’s important to note that the Kolmogorov-Smirnov and Pearson chi-square tests are included here just for reference, as many authors don’t recommend using them when testing for normality (D’Agostino & Belanger, 1990). Learn more about normality tests in Thode (2002).\nI also recommend checking the original papers for each test to understand their assumptions and limitations:\n\n\nAnderson-Darling test: Anderson & Darling (1952); Anderson & Darling (1954).\nBonett-Seier test: Bonett & Seier (2002).\n\nCramér-von Mises test: Cramér (1928); Anderson (1962).\n\nD’Agostino test: D’Agostino (1971); D’Agostino & Pearson (1973).\n\nJarque–Bera test: Jarque & Bera (1980); Bera & Jarque (1981); Jarque & Bera (1987).\n\nLilliefors (K-S) test: Smirnov (1948); Kolmogorov (1933); Massey (1951); Lilliefors (1967); Dallal & Wilkinson (1986).\n\nPearson chi-square test: Pearson (1900).\n\nShapiro-Francia test: Shapiro & Francia (1972).\n\nShapiro-Wilk test: Shapiro & Wilk (1965).\n\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{The data is normally distributed} \\\\\n\\text{H}_{a}: \\text{The data is not normally distributed}\n\\end{cases}\n\\]\nCodefit_engine |&gt;\n  stats::residuals() |&gt;\n  normality_sum()\n\n\nTable 10: Summary of statistical tests conducted to assess the normality of the residuals.\n\n\n\n\n  \n\n\n\n\n\n\nCorrelation between observed residuals and expected residuals under normality.\n\nfit_engine |&gt; olsrr::ols_test_correlation()\n#&gt; [1] 0.9952751\n\nLinearity\nAssumption 3 is satisfied, as the relationship between the variables is fairly linear.\nCodefit |&gt;\n  broom::augment(data) |&gt;\n  ggplot2::ggplot(ggplot2::aes(.pred, .resid)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_hline(\n    yintercept = 0, \n    color = \"black\", \n    linewidth = 0.5,\n    linetype = \"dashed\" \n  ) +\n  ggplot2::geom_smooth(formula = y ~ x, method = \"loess\", color = \"red\") +\n  ggplot2::labs(x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 19: Residual plot showing the relationship between fitted values and residuals, with the dashed black line representing zero residuals, indicating an ideal model fit, and the red line indicating the smoothed conditional mean of residuals, with the shaded region representing the confidence interval of this estimate.\n\n\nCodeplots &lt;- fit_engine |&gt; olsrr::ols_plot_resid_fit_spread(print_plot = FALSE)\n\nfor (i in seq_along(plots)) {\n  q &lt;- plots[[i]] + ggplot2::labs(title = ggplot2::element_blank())\n  \n  q &lt;- q |&gt; ggplot2::ggplot_build()\n  q$data[[1]]$colour &lt;- \"red\"\n  q$plot$layers[[1]]$constructor$color &lt;- \"red\"\n  \n  plots[[i]] &lt;- q |&gt; ggplot2::ggplot_gtable() |&gt; ggplotify::as.ggplot()\n}\n  \ncowplot::plot_grid(plots$fm_plot, plots$rsd_plot, ncol = 2, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 20: Residual fit spread plots to detect non-linearity, influential observations, and outliers. The side-by-side plots show the centered fit and residuals, illustrating the variation explained by the model and what remains in the residuals. Inappropriately specified models often exhibit greater spread in the residuals than in the centered fit. “Proportion Less” indicates the cumulative distribution function, representing the proportion of observations below a specific value, facilitating an assessment of model performance.\n\n\nThe Ramsey’s RESET test indicates that the model has no omitted variables. This test examines whether non-linear combinations of the fitted values can explain the response variable.\nLearn more about the Ramsey’s RESET test in: Ramsey (1969).\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{The model has no omitted variables} \\\\\n\\text{H}_{a}: \\text{The model has omitted variables}\n\\end{cases}\n\\]\n\nCodefit_engine |&gt; lmtest::resettest(power = 2:3)\n#&gt; \n#&gt;  RESET test\n#&gt; \n#&gt; data:  fit_engine\n#&gt; RESET = 1.2564, df1 = 2, df2 = 145, p-value = 0.2878\n\n\n\nCodefit_engine |&gt; lmtest::resettest(type = \"regressor\")\n#&gt; \n#&gt;  RESET test\n#&gt; \n#&gt; data:  fit_engine\n#&gt; RESET = 1.0705, df1 = 4, df2 = 143, p-value = 0.3734\n\n\nHomoscedasticity (common variance)\nAssumption 4 is satisfied, as the residuals exhibit constant variance. While some heteroscedasticity is present, the Breusch-Pagan test (not studentized) indicate that it is not severe.\nWhen comparing the standardized residuals (\\(\\sqrt{|\\text{Standardized Residuals}|}\\)) spread to the fitted values and each predictor, we can observe that the residuals are fairly constant across the range of values. This suggests that the residuals have a constant variance.\nVisual inspection\nCodefit |&gt;\n  stats::predict(data) |&gt;\n  dplyr::mutate(\n    .sd_resid = \n      fit_engine |&gt;\n      stats::rstandard() |&gt; \n      abs() |&gt;\n      sqrt()\n  ) |&gt;\n  ggplot2::ggplot(ggplot2::aes(.pred, .sd_resid)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_smooth(formula = y ~ x, method = \"loess\", color = \"red\") +\n  ggplot2::labs(\n    x = \"Fitted values\", \n    y = latex2exp::TeX(\"$\\\\sqrt{|Standardized \\\\ Residuals|}$\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 21: Relation between the fitted values of the model and its standardized residuals.\n\n\nCodefit |&gt;\n  stats::predict(data) |&gt;\n  dplyr::mutate(\n    .sd_resid = \n      fit_engine |&gt;\n      stats::rstandard() |&gt; \n      abs() |&gt;\n      sqrt()\n  ) |&gt;\n  dplyr::bind_cols(data) |&gt;\n  ggplot2::ggplot(ggplot2::aes(bill_length_mm, .sd_resid)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_smooth(formula = y ~ x, method = \"loess\", color = \"red\") +\n  ggplot2::labs(\n    x = \"Bill length (mm)\", \n    y = latex2exp::TeX(\"$\\\\sqrt{|Standardized \\\\ Residuals|}$\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 22: Relation between bill_length_mm and the model standardized residuals.\n\n\nCodefit |&gt;\n  stats::predict(data) |&gt;\n  dplyr::mutate(\n    .sd_resid = \n      fit_engine |&gt;\n      stats::rstandard() |&gt; \n      abs() |&gt;\n      sqrt()\n  ) |&gt;\n  dplyr::bind_cols(data) |&gt;\n  ggplot2::ggplot(ggplot2::aes(bill_depth_mm, .sd_resid)) +\n  ggplot2::geom_point() +\n  ggplot2::geom_smooth(formula = y ~ x, method = \"loess\", color = \"red\") +\n  ggplot2::labs(\n    x = \"Bill depth (mm)\", \n    y = latex2exp::TeX(\"$\\\\sqrt{|Standardized \\\\ Residuals|}$\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 23: Relation between bill_depth_mm and the model standardized residuals.\n\n\nBreusch-Pagan test\nThe Breusch-Pagan test test indicates that the residuals exhibit constant variance.\nLearn more about the Breusch-Pagan test in: Breusch & Pagan (1979) and Koenker (1981).\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{The variance is constant} \\\\\n\\text{H}_{a}: \\text{The variance is not constant}\n\\end{cases}\n\\]\n\nCodefit_engine_2 |&gt; performance::check_heteroscedasticity()\n#&gt; OK: Error variance appears to be homoscedastic (p = 0.887).\n\n\n\nCode# With studentising modification of Koenker\nfit_engine |&gt; lmtest::bptest(studentize = TRUE)\n#&gt; \n#&gt;  studentized Breusch-Pagan test\n#&gt; \n#&gt; data:  fit_engine\n#&gt; BP = 0.64698, df = 2, p-value = 0.7236\n\n\n\nCodefit_engine |&gt; lmtest::bptest(studentize = FALSE)\n#&gt; \n#&gt;  Breusch-Pagan test\n#&gt; \n#&gt; data:  fit_engine\n#&gt; BP = 0.75804, df = 2, p-value = 0.6845\n\n\n\nCode# Using the studentized modification of Koenker.\nfit_engine |&gt; skedastic::breusch_pagan(koenker = TRUE)\n\n\n  \n\n\n\n\nCodefit_engine |&gt; skedastic::breusch_pagan(koenker = FALSE)\n\n\n  \n\n\n\n\nCodelm(form, data = data) |&gt; car::ncvTest()\n#&gt; Non-constant Variance Score Test \n#&gt; Variance formula: ~ fitted.values \n#&gt; Chisquare = 0.02002983, Df = 1, p = 0.88745\n\n\n\nCodefit_engine |&gt; olsrr::ols_test_breusch_pagan()\n#&gt; \n#&gt;  Breusch Pagan Test for Heteroskedasticity\n#&gt;  -----------------------------------------\n#&gt;  Ho: the variance is constant            \n#&gt;  Ha: the variance is not constant        \n#&gt; \n#&gt;              Data               \n#&gt;  -------------------------------\n#&gt;  Response : ..y \n#&gt;  Variables: fitted values of ..y \n#&gt; \n#&gt;         Test Summary          \n#&gt;  -----------------------------\n#&gt;  DF            =    1 \n#&gt;  Chi2          =    0.02002983 \n#&gt;  Prob &gt; Chi2   =    0.8874538\n\n\nWhite’s test\nThe White’s test is a general test for heteroskedasticity. It is a generalization of the Breusch-Pagan test and is more flexible in terms of the types of heteroskedasticity it can detect. It has the same null hypothesis as the Breusch-Pagan test.\nLike the Breusch-Pagan, the results of the White’s test indicate that the residuals exhibit constant variance.\nLearn more about the White’s test in: White (1980).\n\nCodefit_engine |&gt; skedastic::white()\n\n\n  \n\n\n\nIndependence\nAssumption 5 is satisfied. Although the residuals show some autocorrelation, they fall within the acceptable range of the Durbin–Watson statistic (1.5 to 2.5). It’s also important to note that the observations for each predicted value are not related to any other prediction; in other words, they are not grouped or sequenced by any variable (by design) (see Hair (2019, p. 291) for more information).\nMany authors don’t consider autocorrelation tests for linear regression models, as they are more relevant for time series data. However, I include them here just for reference.\nVisual inspection\nCodefit_engine |&gt; \n  residuals() |&gt;\n  forecast::ggtsdisplay(lag.max=30)\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 24: Time series plot of the residuals along with its AutoCorrelation Function (ACF) and Partial AutoCorrelation Function (PACF).\n\n\nCorrelations\nTable 11 shows the relative importance of independent variables in determining the response variable. It highlights how much each variable uniquely contributes to the R-squared value, beyond what is explained by the other predictors.\nCodefit_engine |&gt; olsrr::ols_correlations()\n\n\nTable 11: Correlations between the dependent variable and the independent variables, along with the zero-order, part, and partial correlations. The zero-order correlation represents the Pearson correlation coefficient between the dependent and independent variables. Part correlations indicate how much the R-squared would decrease if a specific variable were removed from the model, while partial correlations reflect the portion of variance in the response variable that is explained by a specific independent variable, beyond the influence of other predictors in the model.\n\n\n\n\n  \n\n\n\n\n\n\nNewey-West estimator\nThe Newey-West estimator is a method used to estimate the covariance matrix of the coefficients in a regression model when the residuals are autocorrelated.\nLearn more about the Newey-West estimator in: Newey & West (1987) and Newey & West (1994).\n\nCodefit_engine |&gt; sandwich::NeweyWest()\n#&gt;                (Intercept) bill_length_mm bill_depth_mm\n#&gt; (Intercept)     47.9244280    -0.35523375   -1.88169574\n#&gt; bill_length_mm  -0.3552337     0.02273440   -0.02735218\n#&gt; bill_depth_mm   -1.8816957    -0.02735218    0.15988029\n\n\nThe Heteroscedasticity and autocorrelation consistent (HAC) estimation of the covariance matrix of the coefficient estimates can also be computed in other ways. The HAC estimator below is a implementation made by Zeileis (2004).\n\nCodefit_engine |&gt; sandwich::vcovHAC()\n#&gt;                (Intercept) bill_length_mm bill_depth_mm\n#&gt; (Intercept)      46.594526    -0.38006697   -1.74915588\n#&gt; bill_length_mm   -0.380067     0.02178345   -0.02441808\n#&gt; bill_depth_mm    -1.749156    -0.02441808    0.14676678\n\n\nDurbin-Watson test\nThe Durbin-Watson test is a statistical test used to detect the presence of autocorrelation at lag 1 in the residuals from a regression analysis. The test statistic ranges from 0 to 4, with a value of 2 indicating no autocorrelation. Values less than 2 indicate positive autocorrelation, while values greater than 2 indicate negative autocorrelation (Fox, 2016).\nA common rule of thumb in the statistical community is that a Durbin-Watson statistic between 1.5 and 2.5 suggests little to no autocorrelation.\nLearn more about the Durbin-Watson test in: Durbin & Watson (1950); Durbin & Watson (1951); and Durbin & Watson (1971).\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{Autocorrelation of the disturbances is 0} \\\\\n\\text{H}_{a}: \\text{Autocorrelation of the disturbances is not equal to 0}\n\\end{cases}\n\\]\n\nCodelmtest::dwtest(fit_engine)\n#&gt; \n#&gt;  Durbin-Watson test\n#&gt; \n#&gt; data:  fit_engine\n#&gt; DW = 1.5744, p-value = 0.004786\n#&gt; alternative hypothesis: true autocorrelation is greater than 0\n\n\n\nCodecar::durbinWatsonTest(fit_engine)\n#&gt;  lag Autocorrelation D-W Statistic p-value\n#&gt;    1       0.1951782      1.574424   0.006\n#&gt;  Alternative hypothesis: rho != 0\n\n\nLjung-Box test\nThe Ljung–Box test is a statistical test used to determine whether any autocorrelations within a time series are significantly different from zero. Rather than testing randomness at individual lags, it assesses the “overall” randomness across multiple lags.\nLearn more about the Ljung-Box test in: Box & Pierce (1970) and Ljung & Box (1978).\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{Residuals are independently distributed} \\\\\n\\text{H}_{a}: \\text{Residuals are not independently distributed}\n\\end{cases}\n\\]\n\nCodefit_engine |&gt;\n  stats::residuals() |&gt;\n  stats::Box.test(type = \"Ljung-Box\", lag = 10)\n#&gt; \n#&gt;  Box-Ljung test\n#&gt; \n#&gt; data:  stats::residuals(fit_engine)\n#&gt; X-squared = 69.011, df = 10, p-value = 0.0000000000688\n\n\nColinearity/Multicollinearity\nNo high degree of colinearity was observed among the independent variables.\nVariance Inflation Factor (VIF)\nThe Variance Inflation Factor (VIF) indicates the effect of other independent variables on the standard error of a regression coefficient. The VIF is directly related to the tolerance value (\\(\\text{VIF}_{i} = 1/\\text{TO}L\\)). High VIF values (larger than ~5 (Struck, 2024)) suggest significant collinearity or multicollinearity among the independent variables (Hair, 2019, p. 265).\nCodediag_sum_plots &lt;- \n  fit_engine_2 |&gt; \n  performance::check_model(panel = FALSE) |&gt;\n  plot() |&gt;\n  rutils::shush()\n\ndiag_sum_plots$VIF + \n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    subtitle = ggplot2::element_blank()\n  ) +\n  ggplot2::theme(\n    legend.position = \"right\",\n    axis.title = ggplot2::element_text(size = 11, colour = \"black\"),\n    axis.text = ggplot2::element_text(colour = \"gray25\"),\n    axis.text.y = ggplot2::element_text(size = 9),\n    legend.text = ggplot2::element_text(colour = \"black\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 25: Variance Inflation Factors (VIF) for each predictor variable. VIFs below 5 are considered acceptable. Between 5 and 10, the variable should be examined. Above 10, the variable must considered highly collinear.\n\n\nCodefit_engine |&gt; olsrr::ols_vif_tol()\n\n\nTable 12: Variance Inflation Factors (VIF) and tolerance values for each predictor variable.\n\n\n\n\n  \n\n\n\n\n\n\nCodefit_engine_2 |&gt; performance::check_collinearity()\n\n\nTable 13: Variance Inflation Factors (VIF) and tolerance values for each predictor variable.\n\n\n\n\n  \n\n\n\n\n\n\nCondition Index\nThe condition index is a measure of multicollinearity in a regression model. It is based on the eigenvalues of the correlation matrix of the predictors. A condition index of 30 or higher is generally considered indicative of significant collinearity (Belsley et al., 2004, pp. 112–114).\nCodefit_engine |&gt; olsrr::ols_eigen_cindex()\n\n\nTable 14: Condition indexes and eigenvalues for each predictor variable.\n\n\n\n\n  \n\n\n\n\n\n\nMeasures of influence\nIn this section, we will check several measures of influence that can be used to assess the impact of individual observations on the model estimates.\nBut first, let’s define some terms:\n\nLeverage points\n\nLeverage is a measure of the distance between individual values of a predictor and other values of the predictor. In other words, a point with high leverage has an x-value far away from the other x-values. Points with high leverage have the potential to influence the model estimates (Hair, 2019, p. 262; Nahhas, 2024; Struck, 2024).\n\nInfluence points\n\nInfluence is a measure of how much an observation affects the model estimates. If an observation with large influence were removed from the dataset, we would expect a large change in the predictive equation (Nahhas, 2024; Struck, 2024).\n\n\nStandardized residuals\nStandardized residuals are a rescaling of the residual to a common basis by dividing each residual by the standard deviation of the residuals (Hair, 2019, p. 264).\n\nCodefit_engine |&gt; stats::rstandard() |&gt; head()\n#&gt;          1          2          3          4          5          6 \n#&gt; -1.5951436 -0.5051311  0.8262662  0.5052708 -0.5028734 -1.3867386\n\n\nCodedplyr::tibble(\n  x = seq_len(nrow(data)),\n  std = stats::rstandard(fit_engine)\n) |&gt;\n  ggplot2::ggplot(\n    ggplot2::aes(x = x, y = std, ymin = 0, ymax = std)\n  ) +\n  ggplot2::geom_linerange(color = \"blue\") +\n  ggplot2::geom_hline(yintercept = 2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = -2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = 3, color = \"red\") +\n  ggplot2::geom_hline(yintercept = -3, color = \"red\") +\n  ggplot2::scale_y_continuous(breaks = seq(-3, 3)) +\n  ggplot2::labs(\n    x = \"Observation\",\n    y = \"Standardized residual\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 26: Standardized residuals for each observation.\n\n\nStudentized residuals\nStudentized residuals are a commonly used variant of the standardized residual. It differs from other methods in how it calculates the standard deviation used in standardization. To minimize the effect of any observation on the standardization process, the standard deviation of the residual for observation \\(i\\) is computed from regression estimates omitting the \\(i\\)th observation in the calculation of the regression estimates (Hair, 2019, p. 264).\n\nCodefit_engine |&gt; stats::rstudent() |&gt; head()\n#&gt;          1          2          3          4          5          6 \n#&gt; -1.6036484 -0.5038475  0.8253699  0.5039871 -0.5015916 -1.3911431\n\n\nCodedplyr::tibble(\n  x = seq_len(nrow(data)),\n  std = stats::rstudent(fit_engine)\n) |&gt;\n  ggplot2::ggplot(\n    ggplot2::aes(x = x, y = std, ymin = 0, ymax = std)\n  ) +\n  ggplot2::geom_linerange(color = \"blue\") +\n  ggplot2::geom_hline(yintercept = 2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = -2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = 3, color = \"red\") +\n  ggplot2::geom_hline(yintercept = -3, color = \"red\") +\n  ggplot2::scale_y_continuous(breaks = seq(-3, 3)) +\n  ggplot2::labs(\n    x = \"Observation\",\n    y = \"Studentized residual\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 27: Studentized residuals for each observation.\n\n\nCodefit |&gt; \n  broom::augment(data) |&gt;\n  dplyr::mutate(\n    std = stats::rstudent(fit_engine)\n  ) |&gt;\n  ggplot2::ggplot(ggplot2::aes(.pred, std)) +\n  ggplot2::geom_point(color = \"blue\") +\n  ggplot2::geom_hline(yintercept = 2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = -2, color = \"black\") +\n  ggplot2::geom_hline(yintercept = 3, color = \"red\") +\n  ggplot2::geom_hline(yintercept = -3, color = \"red\") +\n  ggplot2::scale_y_continuous(breaks = seq(-3, 3)) +\n  ggplot2::labs(\n    x = \"Predicted value\",\n    y = \"Studentized residual\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 28: Relation between studentized residuals and fitted values.\n\n\nCodeplot &lt;- \n  fit_engine |&gt; \n  olsrr::ols_plot_resid_lev(threshold = 2, print_plot = FALSE)\n\nplot$plot +\n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    y = \"Studentized residual\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 29: Relation between studentized residuals and their leverage points.\n\n\nHat values\nThe hat value indicates how distinct an observation’s predictor values are from those of other observations. Observations with high hat values have high leverage and may be, though not necessarily, influential. There is no fixed threshold for what constitutes a “large” hat value; instead, the focus must be on observations with hat values significantly higher than the rest (Hair, 2019, p. 261; Nahhas, 2024).\n\nCodefit_engine |&gt; stats::hatvalues() |&gt; head()\n#&gt;           1           2           3           4           5           6 \n#&gt; 0.007224717 0.013540911 0.011133950 0.020284125 0.031778182 0.008464034\n\n\nCodedplyr::tibble(\n  x = seq_len(nrow(data)),\n  hat = stats::hatvalues(fit_engine)\n) |&gt;\n  ggplot2::ggplot(\n    ggplot2::aes(x = x, y = hat, ymin = 0, ymax = hat)\n  ) +\n  ggplot2::geom_linerange(color = \"blue\") +\n  ggplot2::labs(\n    x = \"Observation\",\n    y = \"Hat value\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 30: Hat values for each observation.\n\n\nCook’s distance\nThe Cook’s D measures each observation’s influence on the model’s fitted values. It is considered one of the most representative metrics for assessing overall influence (Hair, 2019).\nA common practice is to flag observations with a Cook’s distance of 1.0 or greater. However, a threshold of \\(4 / (n - k - 1)\\), where \\(n\\) is the sample size and \\(k\\) is the number of independent variables, is suggested as a more conservative measure in small samples or for use with larger datasets (Hair, 2019).\nLearn more about Cook’s D in: Cook (1977); Cook (1979).\n\nCodefit_engine |&gt; stats::cooks.distance() |&gt; head()\n#&gt;           1           2           3           4           5           6 \n#&gt; 0.006172316 0.001167497 0.002562303 0.001761909 0.002766625 0.005471884\n\n\nCodeplot &lt;- \n  fit_engine |&gt; \n  olsrr::ols_plot_cooksd_bar(type = 2, print_plot = FALSE)\n\n# The following procedure changes the plot aesthetics.\nq &lt;- plot$plot + ggplot2::labs(title = ggplot2::element_blank())\nq &lt;- q |&gt; ggplot2::ggplot_build()\nq$data[[5]]$label &lt;- \"\"\n\nq |&gt; ggplot2::ggplot_gtable() |&gt; ggplotify::as.ggplot()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 31: Cook’s distance for each observation along with a threshold line at \\(4 / (n - k - 1)\\).\n\n\nCodediag_sum_plots &lt;- \n  fit_engine_2 |&gt; \n  performance::check_model(\n    panel = FALSE,\n    colors = c(\"blue\", \"black\", \"black\")\n  ) |&gt;\n  plot() |&gt;\n  rutils::shush()\n\nplot &lt;- \n  diag_sum_plots$OUTLIERS +\n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    subtitle = ggplot2::element_blank(),\n    x = \"Leverage\",\n    y = \"Studentized residuals\"\n  ) +\n  ggplot2::theme(\n    legend.position = \"right\",\n    axis.title = ggplot2::element_text(size = 11, colour = \"black\"),\n    axis.text = ggplot2::element_text(colour = \"gray25\"),\n    axis.text.y = ggplot2::element_text(size = 9)\n  ) +\n  ggplot2::theme_gray()\n\nplot &lt;- plot |&gt; ggplot2::ggplot_build()\n\n# The following procedure changes the plot aesthetics.\nfor (i in c(1:9)) {\n  # \"#1b6ca8\" \"#3aaf85\"\n  plot$data[[i]]$colour &lt;- dplyr::case_when(\n    plot$data[[i]]$colour == \"blue\" ~ ifelse(i == 4, \"red\", \"blue\"),\n    plot$data[[i]]$colour == \"#1b6ca8\" ~ \"black\",\n    plot$data[[i]]$colour == \"darkgray\" ~ \"black\",\n    TRUE ~ plot$data[[i]]$colour\n  )\n}\n\nplot |&gt; ggplot2::ggplot_gtable() |&gt; ggplotify::as.ggplot()\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 32: Relation between studentized residuals and their leverage points. The blue line represents the Cook’s distance. Any points outside the contour lines are influential observations.\n\n\nInfluence on prediction (DFFITS)\nDFFITS (difference in fits) is a standardized measure of how much the prediction for a given observation would change if it were deleted from the model. Each observation’s DFFITS is standardized by the standard deviation of fit at that point (Struck, 2024).\nThe best rule of thumb is to classify as influential any standardized values that exceed \\(2 \\sqrt{(p / n)}\\), where \\(p\\) is the number of independent variables + 1 and \\(n\\) is the sample size (Hair, 2019, p. 261).\nLearn more about DDFITS in: Welsch & Kuh (1977) and Belsley et al. (2004).\n\nCodefit_engine |&gt; stats::dffits() |&gt; head()\n#&gt;           1           2           3           4           5           6 \n#&gt; -0.13680251 -0.05903146  0.08757991  0.07251828 -0.09087143 -0.12853052\n\n\nCodeplot &lt;- fit_engine |&gt; \n  olsrr::ols_plot_dffits(print_plot = FALSE)\n\nplot$plot + ggplot2::labs(title = ggplot2::element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 33: Standardized DFFITS (difference in fits) for each observation.\n\n\nInfluence on parameter estimates (DFBETAS)\nDFBETAS are a measure of the change in a regression coefficient when an observation is omitted from the regression analysis. The value of the DFBETA is in terms of the coefficient itself (Hair, 2019, p. 261). A cutoff for what is considered a large DFBETAS value is \\(2 / \\sqrt{n}\\), where \\(n\\) is the number of observations. (Struck, 2024).\nLearn more about DFBETAS in: Welsch & Kuh (1977) and Belsley et al. (2004).\n\nCodefit_engine |&gt; stats::dfbeta() |&gt; head()\n#&gt;   (Intercept) bill_length_mm bill_depth_mm\n#&gt; 1  0.22258769  -0.0004349836   -0.01466395\n#&gt; 2 -0.13256789  -0.0054345035    0.01760713\n#&gt; 3 -0.06441232   0.0104695960   -0.01681191\n#&gt; 4  0.01139718  -0.0100344675    0.02167424\n#&gt; 5  0.43219781   0.0049023858   -0.03501141\n#&gt; 6 -0.29541826  -0.0058849442    0.02552779\n\n\n\nCodeplots &lt;- fit_engine |&gt; olsrr::ols_plot_dfbetas(print_plot = FALSE)\n\n\nCodeplots$plots[[1]] + \n  ggplot2::labs(title = \"Intercept coefficient\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 34: Standardized DFBETAS values for each observation concerning the intercept coefficient.\n\n\nCodeplots$plots[[2]] + \n  ggplot2::labs(title = \"bill_length_mm coefficient\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 35: DFBETAS values for each observation concerning the bill_length_mm coefficient.\n\n\nCodeplots$plots[[3]] + \n  ggplot2::labs(title = \"bill_depth_mm coefficient\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 36: Standardized DFBETAS values for each observation concerning the bill_depth_mm coefficient.\n\n\nHadi’s measure\nHadi’s measure of influence is based on the idea that influential observations can occur in either the response variable, the predictors, or both.\nLearn more about Hadi’s measure in: Chatterjee & Hadi (2012).\nCodeplot &lt;- \n  fit_engine |&gt; \n  olsrr::ols_plot_hadi(print_plot = FALSE)\n\nplot +\n  ggplot2::labs(\n    title = ggplot2::element_blank(),\n    y = \"Hadi's measure\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 37: Hadi’s influence measure for each observation.\n\n\nCodeplot &lt;- \n  fit_engine |&gt; \n  olsrr::ols_plot_resid_pot(print_plot = FALSE)\n\nplot + ggplot2::labs(title = ggplot2::element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 38: Potential-residual plot classifying unusual observations as high-leverage points, outliers, or a combination of both."
  },
  {
    "objectID": "index.html#testing-the-hypothesis",
    "href": "index.html#testing-the-hypothesis",
    "title": "General linear models",
    "section": "Testing the hypothesis",
    "text": "Testing the hypothesis\nLet’s now come back to our initial hypothesis:\n\nStatement\n\nThe predictors bill_length_mm and bill_depth_mm effectively predict flipper_length_mm.\n\n\n\\[\n\\begin{cases}\n\\text{H}_{0}: \\text{R}^{2}_{\\text{adj}} \\leq 0.5 \\\\\n\\text{H}_{a}: \\text{R}^{2}_{\\text{adj}} &gt; 0.5\n\\end{cases}\n\\]\nIn addition to an adjusted \\(\\text{R}^{2}\\) greater than 0.5, predictors should demonstrate statistically significant associations, and the model assumptions should be satisfied.\nIn the sections above, we confirmed that the model satisfies the assumptions of linearity, normality, homoscedasticity, and independence. (Model validity requirement: True)\nTable 15 shows that the predictors bill_length_mm and bill_depth_mm are statistically significant in predicting flipper_length_mm. (Predictor significance requirement: True)\nCodefit |&gt; \n  broom::tidy() |&gt;\n  janitor::adorn_rounding(5)\n\n\nTable 15: Output from the model fitting process showing the estimated coefficients, standard errors, test statistics, and p-values for the terms in the linear regression model.\n\n\n\n\n  \n\n\n\n\n\n\nWe can see in Table 16 that the adjusted \\(\\text{R}^{2}\\) is lower than 0.5, which means that the model does not explain more than 50% of the variance in the dependent variable (Adjusted R-squared requirement: False).\nCodefit |&gt; \n  broom::glance() |&gt; \n  tidyr::pivot_longer(cols = dplyr::everything()) |&gt;\n  janitor::adorn_rounding(10)\n\n\nTable 16: Summary of model fit statistics showing key metrics including R-squared, adjusted R-squared, sigma, statistic, p-value, degrees of freedom, log-likelihood, AIC, BIC, and deviance.\n\n\n\n\n  \n\n\n\n\n\n\nCodepsychometric::CI.Rsq(\n  rsq = broom::glance(fit)$adj.r.squared,\n  n = nrow(data),\n  k = length(fit_engine$coefficients) - 1,\n  level = 0.95\n)\n\n\nTable 17: Confidence interval for the adjusted R-squared value. LCL correspond to the lower limit, and UCL to the upper limit.\n\n\n\n\n  \n\n\n\n\n\n\nTherefore, we must reject the alternative hypothesis in favor of the null hypothesis.\nEffect size\nIf we would like to interpret the adjusted \\(\\text{R}^{2}\\) value in terms of effect size, we can use the following code:\n\n\nCodefit |&gt; \n  broom::glance() |&gt; \n  magrittr::extract2(\"adj.r.squared\") |&gt;\n  effectsize::interpret_r2(\"cohen1988\")\n#&gt; [1] \"weak\"\n#&gt; (Rules: cohen1988)\n\n\n\n\nCodefit |&gt; \n  broom::glance() |&gt; \n  magrittr::extract2(\"adj.r.squared\") |&gt;\n  effectsize::interpret_r2(\"falk1992\")\n#&gt; [1] \"adequate\"\n#&gt; (Rules: falk1992)"
  },
  {
    "objectID": "index.html#conclusion",
    "href": "index.html#conclusion",
    "title": "General linear models",
    "section": "Conclusion",
    "text": "Conclusion\nFollowing our criteria we can now answer our question:\nCan bill length and bill depth alone effectively predict flipper length in Adélie penguins?\nThe answer is No. The model does not explain more than 50% of the variance in the dependent variable, which means that the predictors bill_length_mm and bill_depth_mm are not effective in predicting flipper_length_mm."
  },
  {
    "objectID": "index.html#final-remarks",
    "href": "index.html#final-remarks",
    "title": "General linear models",
    "section": "Final remarks",
    "text": "Final remarks\nI hope the explanations, visualizations, and code have helped clarify General Linear Models. If you have any questions, feel free to reach out. You can find me on GitHub.\nFor further learning on general linear models, I recommend the following resources:\n\nDeGroot & Schervish (2012)\nCasella & Berger (2002)\nAllen (1997)\nBussab (1988) (pt-BR)\nDalpiaz (n.d.)\nDudek (2020)\nFox (2016)\nHair (2019)\nJohnson & Wichern (2013)\nKuhn & Silge (2022)\nStruck (2024)\n\nAdditionally, I highly recommend Josh Starmer’s StatQuest and Christian Pascual’s Very Normal YouTube channels. The following videos are especially helpful:\n\nStarmer, J. (Nov 18, 2022). Multiple Regression, Clearly Explained!!! [YouTube video]. https://youtu.be/EkAQAi3a4js?si=MfKPGlFcYqfFAM7j\n\nStarmer, J. (Nov 18, 2022). Multiple Regression in R, Step by Step!!! [YouTube video]. https://youtu.be/mno47Jn4gaU?si=oba5odJm8fjeizs0"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "General linear models",
    "section": "References",
    "text": "References\n\n\nAllen, M. P. (1997). Understanding regression analysis. Plenum Press.\n\n\nAnderson, T. W. (1962). On the distribution of the two-sample Cramer-von Mises criterion. The Annals of Mathematical Statistics, 33(3), 1148–1159. https://doi.org/10.1214/aoms/1177704477\n\n\nAnderson, T. W., & Darling, D. A. (1952). Asymptotic theory of certain \"goodness of fit\" criteria based on stochastic processes. The Annals of Mathematical Statistics, 23(2), 193–212. https://www.jstor.org/stable/2236446\n\n\nAnderson, T. W., & Darling, D. A. (1954). A test of goodness of fit. Journal of the American Statistical Association, 49(268), 765–769. https://doi.org/10.1080/01621459.1954.10501232\n\n\nArif, S., & MacNeil, M. A. (2022). Predictive models aren’t for causal inference. Ecology Letters, 25(8), 1741–1745. https://doi.org/10.1111/ele.14033\n\n\nBelsley, D. A., Kuh, E., & Welsch, R. E. (2004). Regression diagnostics: Identifying influential data and sources of collinearity. John Wiley & Sons. https://doi.org/10.1002/0471725153\n\n\nBera, A. K., & Jarque, C. M. (1981). Efficient tests for normality, homoscedasticity and serial independence of regression residuals: Monte Carlo Evidence. Economics Letters, 7(4), 313–318. https://doi.org/10.1016/0165-1765(81)90035-5\n\n\nBonett, D. G., & Seier, E. (2002). A test of normality with high uniform power. Computational Statistics & Data Analysis, 40(3), 435–445. https://doi.org/10.1016/S0167-9473(02)00074-9\n\n\nBox, G. E. P., & Pierce, D. A. (1970). Distribution of residual autocorrelations in autoregressive-integrated moving average time series models. Journal of the American Statistical Association, 65(332), 1509–1526. https://doi.org/10.1080/01621459.1970.10481180\n\n\nBreusch, T. S., & Pagan, A. R. (1979). A simple test for heteroscedasticity and random coefficient variation. Econometrica, 47(5), 1287–1294. https://doi.org/10.2307/1911963\n\n\nBussab, W. de O. (1988). Análise de variância e de regressão: uma introdução (2nd ed.). Atlas.\n\n\nCasella, G., & Berger, R. L. (2002). Statistical inference (2nd ed.). Duxbury.\n\n\nChatterjee, S., & Hadi, A. S. (2012). Regression analysis by example (5th ed.). Wiley.\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2002). Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.). Lawrence Erlbaum Associates.\n\n\nCook, R. D. (1977). Detection of influential observation in linear regression. Technometrics, 19(1), 15–18. https://doi.org/10.1080/00401706.1977.10489493\n\n\nCook, R. D. (1979). Influential observations in linear regression. Journal of the American Statistical Association, 74(365), 169–174. https://doi.org/10.1080/01621459.1979.10481634\n\n\nCramér, H. (1928). On the composition of elementary errors: First paper: Mathematical deductions. Scandinavian Actuarial Journal, 1928(1), 13–74. https://doi.org/10.1080/03461238.1928.10416862\n\n\nD’Agostino, R. B. (1971). An omnibus test of normality for moderate and large size samples. Biometrika, 58(2), 341–348. https://doi.org/10.1093/biomet/58.2.341\n\n\nD’Agostino, R. B., & Belanger, A. (1990). A suggestion for using powerful and informative tests of normality. The American Statistician, 44(4), 316–321. https://doi.org/10.2307/2684359\n\n\nD’Agostino, R. B., & Pearson, E. S. (1973). Tests for departure from normality. Empirical results for the distributions of b2 and √b1. Biometrika, 60(3), 613–622. https://doi.org/10.1093/biomet/60.3.613\n\n\nDallal, G. E., & Wilkinson, L. (1986). An analytic approximation to the distribution of Lilliefors’s test statistic for normality. The American Statistician, 40(4), 294–296. https://doi.org/10.1080/00031305.1986.10475419\n\n\nDalpiaz, D. (n.d.). Applied statistics with R. https://book.stat420.org/\n\n\nDeGroot, M. H., & Schervish, M. J. (2012). Probability and statistics (4th ed.). Addison-Wesley.\n\n\nDudek, B. (2020). Linear models with R: Emphasis on 2-IV models: Basics of multiple regression. https://bcdudek.net/regression1/\n\n\nDurbin, J., & Watson, G. S. (1950). Testing for serial correlation in least squares regression. I. Biometrika, 37(3-4), 409–428. https://doi.org/10.1093/biomet/37.3-4.409\n\n\nDurbin, J., & Watson, G. S. (1951). Testing for serial correlation in least squares regression. II. Biometrika, 38(1-2), 159–178. https://doi.org/10.1093/biomet/38.1-2.159\n\n\nDurbin, J., & Watson, G. S. (1971). Testing for serial correlation in least squares regression. III. Biometrika, 58(1), 1–19. https://doi.org/10.1093/biomet/58.1.1\n\n\nFox, J. (2016). Applied regression analysis and generalized linear models (3rd ed.). Sage.\n\n\nGorman, K. B., Williams, T. D., & Fraser, W. R. (2014). Ecological sexual dimorphism and environmental variability within a community of antarctic penguins (genus pygoscelis). PLOS ONE, 9(3), e90081. https://doi.org/10.1371/journal.pone.0090081\n\n\nGreener, R. (2020, August 4). Stop testing for normality. Medium. https://towardsdatascience.com/stop-testing-for-normality-dba96bb73f90\n\n\nHair, J. F. (2019). Multivariate data analysis (8th ed.). Cengage.\n\n\nJarque, C. M., & Bera, A. K. (1980). Efficient tests for normality, homoscedasticity and serial independence of regression residuals. Economics Letters, 6(3), 255–259. https://doi.org/10.1016/0165-1765(80)90024-5\n\n\nJarque, C. M., & Bera, A. K. (1987). A test for normality of observations and regression residuals. International Statistical Review, 55(2), 163–172. https://doi.org/10.2307/1403192\n\n\nJohnson, R., & Wichern, D. (2013). Applied multivariate statistical analysis: Pearson new international edition (6th ed.). Pearson.\n\n\nKoenker, R. (1981). A note on studentizing a test for heteroscedasticity. Journal of Econometrics, 17(1), 107–112. https://doi.org/10.1016/0304-4076(81)90062-2\n\n\nKolmogorov, A. (1933). Sulla determinazione empirica di una legge di distribuzione. Giornale dell’Istituto Italiano degli Attuari, 4.\n\n\nKozak, M., & Piepho, H.-P. (2018). What’s normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions. Journal of Agronomy and Crop Science, 204(1), 86–98. https://doi.org/10.1111/jac.12220\n\n\nKuhn, M., & Silge, J. (2022). Tidy modeling with R: A framework for modeling in the tidyverse. O’Reilly Media. https://www.tmwr.org/\n\n\nLilliefors, H. W. (1967). On the Kolmogorov-Smirnov test for normality with mean and variance unknown. Journal of the American Statistical Association, 62(318), 399–402. https://doi.org/10.1080/01621459.1967.10482916\n\n\nLjung, G. M., & Box, G. E. P. (1978). On a measure of lack of fit in time series models. Biometrika, 65(2), 297–303. https://doi.org/10.1093/biomet/65.2.297\n\n\nMassey, F. J. (1951). The Kolmogorov-Smirnov test for goodness of fit. Journal of the American Statistical Association, 46(253), 68–78. https://doi.org/10.1080/01621459.1951.10500769\n\n\nNahhas, R. W. (2024). Introduction to regression methods for public health using R. https://www.bookdown.org/rwnahhas/RMPH/\n\n\nNewey, W. K., & West, K. D. (1987). A simple, positive semi-definite, heteroskedasticity and autocorrelation consistent covariance matrix. Econometrica, 55(3), 703–708. https://doi.org/10.2307/1913610\n\n\nNewey, W. K., & West, K. D. (1994). Automatic lag selection in covariance matrix estimation. The Review of Economic Studies, 61(4), 631–653. https://doi.org/10.2307/2297912\n\n\nNeyman, J., & Pearson, E. S. (1928a). On the use and interpretation of certain test criteria for purposes of statistical inference: Part I. Biometrika, 20A(1/2), 175–240. https://doi.org/10.2307/2331945\n\n\nNeyman, J., & Pearson, E. S. (1928b). On the use and interpretation of certain test criteria for purposes of statistical inference: Part II. Biometrika, 20A(3/4), 263–294. https://doi.org/10.2307/2332112\n\n\nPearson, K. (1900). X. On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 50(302), 157–175. https://doi.org/10.1080/14786440009463897\n\n\nPeek, M. S., Leffler, A. J., Flint, S. D., & Ryel, R. J. (2003). How much variance is explained by ecologists? Additional perspectives. Oecologia, 137(2), 161–170. https://www.jstor.org/stable/4223745\n\n\nPerezgonzalez, J. D. (2015). Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing. Frontiers in Psychology, 6. https://doi.org/10.3389/fpsyg.2015.00223\n\n\nPopper, K. R. (1979). Objective knowledge: An evolutionary approach. Oxford University Press.\n\n\nRamsey, J. B. (1969). Tests for specification errors in classical linear least-squares regression analysis. Journal of the Royal Statistical Society. Series B (Methodological), 31(2), 350–371. https://doi.org/10.1111/j.2517-6161.1969.tb00796.x\n\n\nSchucany, W. R., & Ng, H. K. T. (2006). Preliminary goodness-of-fit tests for normality do not validate the one-sample Student t. Communications in Statistics - Theory and Methods, 35(12), 2275–2286. https://doi.org/10.1080/03610920600853308\n\n\nShapiro, S. S., & Francia, R. S. (1972). An approximate analysis of variance test for normality. Journal of the American Statistical Association, 67(337), 215–216. https://doi.org/10.1080/01621459.1972.10481232\n\n\nShapiro, S. S., & Wilk, M. B. (1965). An analysis of variance test for normality (complete samples)†. Biometrika, 52(3-4), 591–611. https://doi.org/10.1093/biomet/52.3-4.591\n\n\nShatz, I. (2024). Assumption-checking rather than (just) testing: The importance of visualization and effect size in statistical diagnostics. Behavior Research Methods, 56(2), 826–845. https://doi.org/10.3758/s13428-023-02072-x\n\n\nSmirnov, N. (1948). Table for estimating the goodness of fit of empirical distributions. Annals of Mathematical Statistics, 19, 279–281.\n\n\nStruck, J. (2024). Regression Diagnostics with R. University of Wisconsin-Madison. https://sscc.wisc.edu/sscc/pubs/RegDiag-R/\n\n\nThode, H. C. (2002). Testing for normality. Marcel Dekker.\n\n\nWelsch, R., & Kuh, E. (1977). Linear regression diagnostics (Working Paper 0173; p. 44). National Bureau of Economic Research. https://doi.org/10.3386/w0173\n\n\nWhite, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. Econometrica, 48(4), 817–838. https://doi.org/10.2307/1912934\n\n\nZeileis, A. (2004). Econometric computing with HC and HAC covariance matrix estimators. Journal of Statistical Software, 11(10), 1–17. https://doi.org/10.18637/jss.v011.i10"
  }
]